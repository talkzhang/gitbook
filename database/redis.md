# redis AOF持久化文件越来越大这么办？

这里不说rdb，就说AOF记录的是什么，AOF记录的是每次执行的所有命令行，所以AOF文件中的内容会越来越多，文件的体积也会越来越大，如果不加以控制的话，体积过大的 AOF文件很可能对Redis服务器、甚至整个宿主计算机造成影响，并且AOF文件的体积越大，使用AOF文件来进行数据还原所需的时间就越多

示例：

```bash
redis> RPUSH list "A" "B"          

结果：["A", "B"]

redis> RPUSH list "C"                        

结果：["A", "B", "C"]

redis> RPUSH list "D" "E"            

结果：["A", "B", "C", "D", "E"]

redis> LPOP list                     

结果：["B", "C", "D", "E"]

redis> LPOP list                     

结果：["C", "D", "E"]
```

为了解决AOF文件体积膨胀的问题，Redis提供了AOF文件重写（rewrite）功能，创建一个新的AOF文件来替代现有的AOF文件，新旧文件所保存的数据库状态相同，但新AOF文件不会包含任何冗余命令，所以体积会比旧的小得多

## aof重写实现原理

例如上面的例子，如果想要用尽量少的命令来记录list键的状态，那么最简单高效的办法不是去读取和分析现有AOF文件的内容，而是直接从数据库中读取键list的值，然后执行

```bash
RPUSH list "C" "D" "E" 
```

这一条命令就可以代替之前的5条命令，就可以将保存list键所需的命令从5条减少为一条了


首先从数据库中读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令；可以对执行的一大堆命令行优化成更少条的命令，所以优化之后aof的文件体积肯定会小很多。

## aof后台重写

重写会进行大量的写入操作，会阻塞服务器线程，无法处理新的命令请求

为解决这个问题，Redis将AOF重写程序放到子进程里执行，这样，父进程就可以继续处理命令请求

但同时也会产生一个新的问题，子进程在进行AOF重写期间，服务器进程还需要继续处理命令请求，而新的命令可能会对现有的数据库状态进行修改，从而产生数据库状态不一致

为了解决数据不一致问题，Redis服务器设置了一个AOF重写缓冲区，这个缓冲区在服务器创建子进程之后开始使用，当服务器执行完一个写命令之后，它会将这个写命令发送给AOF重写缓冲区

当子进程完成AOF重写工作之后，它会向父进程发送一个信号，父进程在接到该信号之后，会调用信号处理函数，执行以下工作：

1）将AOF重写缓冲区中的所有内容写入到新AOF文件中，这时新AOF文件与当前的数据库状态一致

2）对新的AOF文件进行改名，原子地覆盖现有的AOF文件，完成新旧两个AOF文件的替换

在整个AOF后台重写过程中，只有信号处理函数执行时会对服务器造成阻塞

![](https://cdn.jsdelivr.net/gh/talkzhang/imgs-bed@master/image/20210628105601.png)

# redis为什么快

## 1、redis是基于内存来进行操作

内存操作要快于磁盘操作很多倍，减少磁盘io，所以redis基于内存操作会很快，至于磁盘操作，如果你设置了数据持久化，redis会在后台有别的线程去异步这个事

## 2、redis利用io多路复用  使操作不必在用户态和内核态之间来回切换

redis使用单线程来处理客户端请求，是基于Reactor单线程模式实现，通过IO多路复用程序接收到用户的请求后，全部推送到一个队列里，交给文件分派器进行处理。

io多路复用是非阻塞io，什么意思呢，举例比如说一个餐厅一个服务员，客人点餐时，服务员在那等着，后面的顾客也都等着服务员点菜，这就是阻塞式io；当顾客点餐时，服务员去招待别的顾客等顾客点好了喊话服务员告诉点完了，这种叫非阻塞io。

同时redis自己集成了一套事件驱动，将需要做的事抽象为事件，处理完成后返回给客户端同时解除绑定的连接。

![](https://cdn.jsdelivr.net/gh/talkzhang/imgs-bed@master/image/20220517113250.png)

redis6.0之后支持了多线程模式，虽然是多线程，但也不是说设置越多越好，毕竟有上下文切换的开销，Redis的多线程模型，不是传统意义上的多线程并发，而是把socket解析回写的这部分操作并行化，以解决IO上的时间消耗带来的系统瓶颈。

![](https://cdn.jsdelivr.net/gh/talkzhang/imgs-bed@master/image/20220517113410.png)

## 3、redis底层数据结构的优化

redis针对客户端连接支持5种数据格式，但这里说的数据结构优化不是说这个，这5种数据格式在底层有redis优化的数据结构的支撑，分别有sds动态字符串、双端列表、ziplist压缩列表、hash表、整型数组、skiplist列表。

![](https://cdn.jsdelivr.net/gh/talkzhang/imgs-bed@master/image/20220516164709.png)

比如sds动态字符串，是在c支持的字符串上进行了优化，该字符串维护了字符串长度，因为c默认字符串是以**\0**，且在获取字符串长度是遍历整理字符串来获取的，有了字符串长度直接就可以获取到；同时动态字符串在空间分配上支持了预分配，大概意思就是有个字段用来存储每个字符串空闲的空间，当然空闲空间分配里面有它的规则，这样做的好处就是比如当字符串长度缩短，不需要在重新分配空间了，而是把缩短后减少的空间记录起来，等有类似append操作时优先使用多出记录的空闲空间即可，这样做减少了空间的分配。

再比如说hash表，redis 也是通过链表来解决hash冲突的，但是链表长度过长也会影响效率，所以redis使用两个全局hash表，当hash1表冲突过多链表过长，触发rehash操作，为将hash2表申请更大的内存空间，然后将hash1表的数据重新映射拷贝到 hash2中，当然拷贝的过程是渐进拷贝非全量一次性操作，否则会影响redis性能，最后会将hash1表空间释放。

最后说下skiplist，sorted set的实现就是通过它来实现的， 它的大致思路是通过对数组分层，越高层指向的index越少，只有最低层是原数组形态，并且数组是有序的，这样在查找某条数据从上到下可以减少查询次数，这个操作对比红黑树有哪些优势呢？

### 为啥 redis 使用跳表(skiplist)而不是使用 red-black

1. skiplist的复杂度和红黑树一样，而且实现起来更简单。
2. 在并发环境下skiplist有另外一个优势，红黑树在插入和删除的时候可能需要做一些rebalance的操作，这样的操作可能会涉及到整个树的其他部分，而skiplist的操作显然更加局部性一些，锁需要盯住的节点更少，因此在这样的情况下性能好一些。

# redis的雪崩、穿透、击穿

## 雪崩

是指缓存中的大量key在同一时间失效，导致大量请求跑到了数据库，此时数据库容易扛不住发生宕机的风险。

解决方案：第一首先考虑设置key时过期时间可以设置一个随机范围，避免大家一起失效；第二，为了防止数据库发生宕机风险，可以考虑在服务层限流降级，比如阿里巴巴sentinel，hystrix都可以实现这种功能，其实这个就跟微博上一个热点大家都取看有的人能看到，有的人看不到，刷几次就看到了，就是限流降级的意思。

## 穿透

是指一个key在redis中不存在，在数据库也不存在，这样每次都会刷到数据库，产生一些没必要的查询浪费资源。

解决方案：可以考虑将这些数据库也查不到的数据放入到缓存中，比如设置value为unknow；增强入参校验，比如查询时给的数据库自增id是负数的可以直接从哪个服务层拦截掉

## 击穿

就是说某个热点key失效后，导致并发访问该key的所有请求全部打到数据库取查询，这种情况叫做缓存击穿。

解决方案：热点key考虑设置永不过期；或者考虑使用分布式锁来解决该问题，保证去数据库查询时只有某一个线程获取到后放入缓存；

# 批量操作

redis的批量操作大致分为两种，一种是基于服务端实现的，例如lmget、lmset、mset、mget，是通过服务器端实现的，所以可以保证批量操作的原子性；还有pipline管道，是通过客户端和服务端一起实现的，该操作不保证执行的原子性。

# 如何保证双写一致性

其实数据库和缓存的一致性，核心就是做到最终让数据库和缓存的操作原子性，当然要视情况而定，做到最终一致性绝大部分系统都可以接受。

首先读操作，先从缓存内查找，找到则直接响应客户端，如果没有找到则直接去数据库内查找，同时放入缓存内，最后响应客户端。

写操作，在更新数据库操作完成后删除缓存，为什么不直接更新缓存呢，是因为由于网络延迟可能导致多个线程执行数据更新的顺序不一致导致缓存数据不准确，所以直接删掉，但是如果更新成功，删除缓存失败怎么办，可以考虑将删除失败的缓存key放入一个消息队列，由消息队列完成重试删除操作；或者如果说该缓存涉及面不广，比如只是一个单表的缓存值，那么是否可以考虑将更新和删除操作放到一个事务内，如果删除缓存失败直接回滚，也是一种选择吧。

# redis 事务

multi开启事务，async提交事务。其实一般也不用，只是人家有这个功能而已。

# redis分布式锁怎么用的 有什么缺点

通过setnx指令实现，使用setnx可以保证该命令只给缓存中不存在的key设置过期时间，我们设置过期时间单位使用ex（秒）来控制的，在释放的时候通过lua脚本来保证释放指令的原子性，即判断后释放。

有成熟的框架也支持redis分布式锁，比如redission，它的实现原理就是在上锁和解锁都使用了lua脚本来执行，同时会有一个watch dog线程在监控持有锁的线程每隔10s是否还在执行，如果还在执行则给当前持有锁的key续时，在释放时也是通过lua脚本来实现的。

redis锁缺点：1、服务器时钟问题，如果服务器时钟向前跳跃，比如服务器比客户端时钟快了2分钟，设置锁的失效的时间是12.02，那么服务器会在12点钟就将锁提前释放，有可能导致多个客户端同时获取一把锁；2、单节点故障问题，如果redis是主从+哨兵模式部署，当客户端1上锁成功后，上锁的动作肯定是master完成的，然后会异步同步到slave节点，此时如果master宕机，会选举出新的master，但是客户端1的锁还没有同步过来，会导致多个客户端都持有锁。

# redis和memcache的区别

redis支持持久化，memcache只支持内存操作；redis天生支持集群模式，memcache需要结合其他组件来完成比较繁琐；redis支持更多的数据类型，memcache只支持字符串；丰富的场景，redis支持事务、消息队列，memcache据我所知应该没有这些能力。

# redis内存过期策略、内存淘汰机制

在redis内部，如果某一个key设置了过期时间，到期后redis会进行删除，在key过期处理上，redis采用定时扫描删除+惰性删除，定式扫描是指在服务器内部通过定时任务每隔一段时间扫描进行删除，由于全量扫描会消耗巨大资源，所以redis总是随机抓取一部分key来查看是否过期，如果过期就会删除；每次随机扫描的key覆盖肯定不够完整，所以当客户端查询某个key如果发现是过期时，会执行删除动作，这两种机制来处理过期的key可能还会有存在一些本该过期删除的key在redis内存中。所以呀，redis是很有可能发生内存不足的情况的。

Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。

* no-eviction：当内存不足以容纳新写入数据时，新写入操作会报错。
* allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。
* allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。
* volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。
* volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
* volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。

这几种策略也很好记忆，首先默认redis内存不足时，不让写入，直接抛出异常；其次就是移除少使用、或者随机移除；再就是针对设置了过期时间的key，移除哪些少使用、或者随机移除、或者马上要过期的进行移除。

需要注意的地方是，redis的过期策略针对的过期的key的处理方式；而内存淘汰是针对内存不足时的处理方法，这两者没什么直接联系。

# redis如何支持持久化的

redis有两种方式可以将数据持久化，

一种是rdb快照，是存的元数据文件，特点是可以生成某一时刻的数据快照文件，优点该文件是进行过压缩优化的，体积相对较小，恢复数据肯定是比较快的，因为它本身就是数据文件；缺点是由于该操作是基于内存和cpu，每次凑从父级进程fork出子进程copy来完成，所以特别消耗内存和cpu，所以一般使用时频率不宜过大，且因为它是备份某一时刻的数据，所以有可能会丢失更多的数据。

另一种是aof，存的是执行的写操作命令，支持实时或者每隔n秒将执行的写操作持久化到磁盘，由于记录命令肯定会导致文件过大，所以redis可以设置当文件到达多大时进行瘦身优化，但是这种操作还是比较复杂的，容易出现bug导致数据不完整或者不一致，且也比较消耗cpu，它的优点就是丢失数据更少，缺点就是宕机后恢复起来还是比较慢的毕竟是命令需要处理解析方面的动作，没有rdb快。

在生产环境使用时，可以结合实际使用场景来使用持久化机制，既可以单独使用aof或者rdb，也可以两者结合使用。

